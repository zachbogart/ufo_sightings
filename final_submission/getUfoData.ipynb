{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFO Data Scraping\n",
    "### source: www.nuforc.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will scrape ufo observation data from the NUFORC website. The script was executed on a Microsoft Azure cloud server and takes approximately 10 hours to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a class object to parse the html table from each web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTMLTableParser:\n",
    "\n",
    "    def parse_html_table(self, table):\n",
    "        n_columns = 0\n",
    "        n_rows=0\n",
    "        column_names = []\n",
    "\n",
    "        # Find number of rows and columns\n",
    "        # we also find the column titles if we can\n",
    "        for row in table.find_all('tr'):\n",
    "\n",
    "            # Determine the number of rows in the table\n",
    "            td_tags = row.find_all('td')\n",
    "            if len(td_tags) > 0:\n",
    "                n_rows+=1\n",
    "                if n_columns == 0:\n",
    "                    # Set the number of columns for our table\n",
    "                    n_columns = len(td_tags)\n",
    "\n",
    "            # Handle column names if we find them\n",
    "            th_tags = row.find_all('th') \n",
    "            if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                for th in th_tags:\n",
    "                    column_names.append(th.get_text())\n",
    "\n",
    "        # Safeguard on Column Titles\n",
    "        if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "            raise Exception(\"Column titles do not match the number of columns\")\n",
    "\n",
    "        columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "        df = pd.DataFrame(columns = columns,\n",
    "                          index= range(0,n_rows))\n",
    "        row_marker = 0\n",
    "        for row in table.find_all('tr'):\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                df.iat[row_marker,column_marker] = column.get_text()\n",
    "                column_marker += 1\n",
    "            if len(columns) > 0:\n",
    "                row_marker += 1\n",
    "\n",
    "        # Convert to float if possible\n",
    "        for col in df:\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the HTMLTableParser class defined, we then go through all of the possible webpages (one per month), and within each monthly webpage, the script will find the clickthrough links to get the detailed descriptions of the observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f072953cc885413bbf3079cd0fcb6f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=681), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "baseURL = \"http://www.nuforc.org/webreports/\"\n",
    "monthrange = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "yearrange = range(1338,2019)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for year in tq(yearrange):\n",
    "    for month in monthrange:\n",
    "        url = baseURL + \"ndxe\" + str(year) + month + \".html\"\n",
    "        r = req.get(url)\n",
    "        if r.status_code == 404:\n",
    "            pass\n",
    "        else:\n",
    "            c = r.text\n",
    "            soup = BeautifulSoup(c, 'html.parser')\n",
    "            html_table = soup.find_all('table')[0]\n",
    "            parser = HTMLTableParser()\n",
    "            table = parser.parse_html_table(html_table)\n",
    "            table['year'] = year\n",
    "            table['month'] = month\n",
    "            links = html_table.find_all('a')\n",
    "            descriptions = []\n",
    "            for link in links:\n",
    "                try:\n",
    "                    ext = link.attrs['href']\n",
    "                    singleURL = baseURL + ext\n",
    "                    r = req.get(singleURL)\n",
    "                    c = r.text\n",
    "                    soup = BeautifulSoup(c, 'html.parser')\n",
    "                    html_table = soup.find_all('table')[0]\n",
    "                    parser = HTMLTableParser()\n",
    "                    singleTable = parser.parse_html_table(html_table)\n",
    "                    descriptions.append(singleTable.loc[[1]]['Sighting Report'])\n",
    "                except:\n",
    "                    descriptions.append(\"\")\n",
    "            table['Desc'] = descriptions\n",
    "            data = data.append(table)\n",
    "# data = data.dropna(subset=['Date / Time','City']).drop(0,axis=1)\n",
    "data.to_csv('ufo_data_fullDescs.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
